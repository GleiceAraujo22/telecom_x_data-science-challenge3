# üìä Telecom X ‚Äì Parte 2: Previs√£o de Evas√£o de Clientes (Churn)  
 
## üìå Descri√ß√£o do Projeto
 Este projeto √© a parte 2 de uma an√°lise explorat√≥ria dos dados onde nessa etapa iremos construir modelos de machine learning para previs√£o de evas√£o de clientes de uma empresa de telecomunica√ß√µes. Utilizamos t√©cnicas avan√ßadas de an√°lise de dados, machine learning e balanceamento de dados para identificar os principais fatores e padr√µes que contribuem para evas√£o de clientes. 

 ## üõ† Tecnologias Utilizadas
* Python 3.x
* Pandas, NumPy (manipula√ß√£o e an√°lise de dados)
* Matplotlib
* Scikit-learn

 ## ü§ñ Modelos de Machine learning
  * **DummyRegressor (modelo baseline)**: Serve como refer√™ncia, pois faz previs√µes simples sem realmente aprender com os dados. Ele mostra o desempenho m√≠nimo esperado e ajuda a avaliar se outros modelos realmente agregam valor.
    
  * **Decision Tree**: Modelo f√°cil de interpretar, pois segue uma l√≥gica de ‚Äúse-ent√£o‚Äù(fluxograma). Pode capturar rela√ß√µes n√£o lineares, mas tende a sofrer com overfitting se n√£o houver regulariza√ß√£o.
    
  * **Regress√£o Log√≠stica**: Um modelo estat√≠stico cl√°ssico para classifica√ß√£o bin√°ria. √â simples, interpret√°vel e eficiente, mas pode ter limita√ß√µes em capturar rela√ß√µes complexas entre vari√°veis.
    
  * **Random Forest**: Conjunto de v√°rias √°rvores de decis√£o (Ensemble), reduzindo o risco de overfitting e melhorando a robustez. Costuma ter bom desempenho em problemas de classifica√ß√£o como churn, pois equilibra interpretabilidade e capacidade preditiva, capturando padr√µes mais complexos nos dados.


## üìä An√°lise dos Modelos Treinados  

### Estrat√©gia para lidar com o desbalanceamento entre as classes da vari√°vel alvo (Churn)

O dataset apresentava um desbalanceamento significativo entre clientes que deram churn e os que permaneceram. Para lidar com esse problema, foi utilizada a estrat√©gia `class_weight="balanced"`, que ajusta automaticamente os pesos das classes de acordo com sua frequ√™ncia.

Essa abordagem foi escolhida por alguns motivos:

**Preserva os dados originais**: diferentemente de t√©cnicas como SMOTE, n√£o h√° cria√ß√£o artificial de novas amostras, evitando risco de introduzir ru√≠do.

**Integra√ß√£o direta ao modelo**: o ajuste √© feito internamente no algoritmo de classifica√ß√£o, garantindo simplicidade e efici√™ncia.

**Equil√≠brio no aprendizado**: permite que o modelo atribua maior import√¢ncia √† classe minorit√°ria, reduzindo a tend√™ncia de prever apenas a classe majorit√°ria.

Em resumo, o uso de class_weight="balanced" proporcionou uma forma pr√°tica e confi√°vel de lidar com o desbalanceamento, mantendo a integridade dos dados e evitando vieses no processo de modelagem.  


![distribuicao churn](visualizations/distribuicao_churn.png)

--- 

### Estrat√©gia para lidar com a multicolinearidade 
O VIF (Variance Inflation Factor) foi utilizado no projeto para identificar e mitigar problemas de multicolinearidade entre as vari√°veis independentes. A multicolinearidade ocorre quando duas ou mais vari√°veis explicativas est√£o altamente correlacionadas entre si, o que pode distorcer os coeficientes do modelo, dificultando a interpreta√ß√£o dos resultados e reduzindo a robustez das estimativas. Dessa forma, foi poss√≠vel avaliar quais vari√°veis apresentavam redund√¢ncia de informa√ß√£o e tomar decis√µes mais conscientes sobre manter ou remover vari√°veis no modelo. 

Optei por utilizar essa t√©cnica para n√£o prejudicar o modelo de regress√£o log√≠stica visto que para os modelos de √Årvore que tamb√©m foram utilizados, a multicolinearidade tem um impacto menor mas ainda sim pode haver benef√≠cios.   

| Faixa de VIF          | Interpreta√ß√£o                   |
|-----------------------|---------------------------------|
| VIF ‚âà 1               | Sem multicolinearidade          |
| 1 < VIF < 5           | Baixa (aceit√°vel)               |
| 5 ‚â§ VIF < 10          | Moderada (acompanhar)           |
| VIF ‚â• 10              | Alta (aten√ß√£o!)                 |
| VIF = ‚àû (infinito)    | Multicolinearidade perfeita ‚ö†Ô∏è |


* Exemplo de VIF gerado:  

| Vari√°vel                           | VIF        |
|-----------------------------------|-----------|
| const                              | 31.308484 |
| Charges.Monthly                    | 22.356986 |
| InternetService_Fiber optic        | 7.554042  |
| tenure                             | 2.784158  |
| Contract_Two year                  | 2.610640  |
| StreamingMovies_Yes                | 2.417216  |
| StreamingTV_Yes                    | 2.400758  |
| PaymentMethod_Electronic check     | 1.973409  |
| TechSupport_Yes                    | 1.850009  |
| PaymentMethod_Mailed check         | 1.840793  |
| OnlineSecurity_Yes                 | 1.810495  |
| DeviceProtection_Yes               | 1.784591  |
| OnlineBackup_Yes                   | 1.708249  |
| MultipleLines_Yes                  | 1.630113  |
| Contract_One year                  | 1.620312  |
| PhoneService_Yes                   | 1.609719  |
| PaymentMethod_Credit card (automatic) | 1.560356 |
| Partner_Yes                        | 1.462143  |
| Dependents_Yes                     | 1.383601  |
| PaperlessBilling_Yes               | 1.208148  |
| SeniorCitizen                      | 1.153343  |
| gender_Male                        | 1.001830  |

--- 
### Matriz de confus√£o e m√©tricas de avalia√ß√£o 

A matriz de confus√£o √© importante porque permite avaliar detalhadamente o desempenho de um modelo de classifica√ß√£o, mostrando quantos casos foram corretamente ou incorretamente classificados para cada classe. Ela fornece insights sobre acertos, erros e desequil√≠brios entre classes, complementando m√©tricas como acur√°cia, precis√£o, recall e F1-score. 

O foco principal no projeto s√£o em clientes que abandonam o servi√ßo (Churn = 1) por√©m como naturalmente s√£o dados desbalanceados (a propor√ß√£o de clientes que abandonam √© menor do que a propor√ß√£o de clientes ativos) 

![](visualizations/confusion_matrix_logistic.png) 
  

--- 
![](visualizations/confusion_matrix_dt.png)  

--- 
![](visualizations/confusion_matrix_rf.png)   

--- 
![Curva ROC - Regress√£o log√≠stica](visualizations/roc_curve_logistic_r.png) 

--- 
![Curva ROC - Decision tree](visualizations/roc_curve_dt.png)  

--- 
![Curva ROC - Random Forest](visualizations/roc_curve_rf.png)  

## An√°lise de Import√¢ncia das Vari√°veis 

![permutation importance - Regress√£o Log√≠stica](visualizations/permutation_importance_logistic.png)   

--- 

![permutation importance - Random Forest](visualizations/permutation_importance_rf.png)    

## Desempenho dos Modelos

Os modelos com melhor desempenho foram: Random Forest e Regress√£o Log√≠stica, estes apresentaram desempenho consistente na previs√£o de clientes propensos a churn:

**Recall(m√©trica principal neste projeto)**: alta capacidade de identificar clientes que realmente cancelariam, permitindo a√ß√µes preventivas mais eficazes.

**Precis√£o e F1-score**: equil√≠brio adequado entre falsos positivos e falsos negativos.

**AUC-ROC**: [ex.: 0.84], indicando bom poder discriminativo do modelo.

Estes modelos mostraram-se robustos e interpret√°veis, sendo poss√≠vel extrair insights das vari√°veis mais importantes para o neg√≥cio.  

## Pr√≥ximos passos 
* Otimizar hiperpar√¢metros
* Treinar outros modelos de machine learning poss√≠veis como XGBoost com foco na melhora de performance preditiva.
* Feature engineering
