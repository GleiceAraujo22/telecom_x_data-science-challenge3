# üìä Telecom X ‚Äì Parte 2: Previs√£o de Evas√£o de Clientes (Churn) - Machine Learning
 
## üìå Descri√ß√£o do Projeto
 Este projeto √© a parte 2 de uma an√°lise explorat√≥ria dos dados onde nessa etapa constru√≠mos modelos de machine learning para previs√£o de evas√£o de clientes de uma empresa de telecomunica√ß√µes. Utilizamos t√©cnicas avan√ßadas de an√°lise de dados, machine learning e balanceamento de dados para identificar os principais fatores e padr√µes que contribuem para evas√£o de clientes.  

 üìä [Veja o projeto completo aqui](notebooks/Telecomx_projeto_churn_parte2_ml(1).ipynb)

 ## üõ† Tecnologias Utilizadas
* Python 3.x
* Pandas, NumPy (manipula√ß√£o e an√°lise de dados)
* Matplotlib
* Scikit-learn

 ## ü§ñ Modelos de Machine learning
  * **DummyRegressor (modelo baseline)**: Serve como refer√™ncia, pois faz previs√µes simples sem realmente aprender com os dados. Ele mostra o desempenho m√≠nimo esperado e ajuda a avaliar se outros modelos realmente agregam valor.
    
  * **Decision Tree**: Modelo f√°cil de interpretar, pois segue uma l√≥gica de ‚Äúse-ent√£o‚Äù(fluxograma). Pode capturar rela√ß√µes n√£o lineares, mas tende a sofrer com overfitting se n√£o houver regulariza√ß√£o.
    
  * **Regress√£o Log√≠stica**: Um modelo estat√≠stico cl√°ssico para classifica√ß√£o bin√°ria. √â simples, interpret√°vel e eficiente, mas pode ter limita√ß√µes em capturar rela√ß√µes complexas entre vari√°veis.
    
  * **Random Forest**: Conjunto de v√°rias √°rvores de decis√£o (Ensemble), reduzindo o risco de overfitting e melhorando a robustez. Costuma ter bom desempenho em problemas de classifica√ß√£o como churn, pois equilibra interpretabilidade e capacidade preditiva, capturando padr√µes mais complexos nos dados.


## üìä An√°lise e Desempenho dos Modelos Treinados  

### Estrat√©gia para lidar com o desbalanceamento entre as classes da vari√°vel alvo (Churn)

O dataset apresentava um desbalanceamento significativo entre clientes que deram churn e os que permaneceram. Para lidar com esse problema, foi utilizada a estrat√©gia `class_weight="balanced"`, que ajusta automaticamente os pesos das classes de acordo com sua frequ√™ncia.

Essa abordagem foi escolhida por alguns motivos:

**Preserva os dados originais**: diferentemente de t√©cnicas como SMOTE, n√£o h√° cria√ß√£o artificial de novas amostras, evitando risco de introduzir ru√≠do.

**Integra√ß√£o direta ao modelo**: o ajuste √© feito internamente no algoritmo de classifica√ß√£o, garantindo simplicidade e efici√™ncia.

**Equil√≠brio no aprendizado**: permite que o modelo atribua maior import√¢ncia √† classe minorit√°ria, reduzindo a tend√™ncia de prever apenas a classe majorit√°ria.

Em resumo, o uso de class_weight="balanced" proporcionou uma forma pr√°tica e confi√°vel de lidar com o desbalanceamento, mantendo a integridade dos dados e evitando vieses no processo de modelagem.  


![distribuicao churn](visualizations/distribuicao_churn.png)

--- 

### Estrat√©gia para lidar com a multicolinearidade 
O VIF (Variance Inflation Factor) foi utilizado no projeto para identificar e mitigar problemas de multicolinearidade entre as vari√°veis independentes. A multicolinearidade ocorre quando duas ou mais vari√°veis explicativas est√£o altamente correlacionadas entre si, o que pode distorcer os coeficientes do modelo, dificultando a interpreta√ß√£o dos resultados e reduzindo a robustez das estimativas. Dessa forma, foi poss√≠vel avaliar quais vari√°veis apresentavam redund√¢ncia de informa√ß√£o e tomar decis√µes mais conscientes sobre manter ou remover vari√°veis no modelo. 

Optei por utilizar essa t√©cnica para n√£o prejudicar o modelo de regress√£o log√≠stica visto que para os modelos de √Årvore que tamb√©m foram utilizados, a multicolinearidade tem um impacto menor mas ainda sim pode haver benef√≠cios.   

| Faixa de VIF          | Interpreta√ß√£o                   |
|-----------------------|---------------------------------|
| VIF ‚âà 1               | Sem multicolinearidade          |
| 1 < VIF < 5           | Baixa (aceit√°vel)               |
| 5 ‚â§ VIF < 10          | Moderada (acompanhar)           |
| VIF ‚â• 10              | Alta (aten√ß√£o!)                 |
| VIF = ‚àû (infinito)    | Multicolinearidade perfeita ‚ö†Ô∏è |


* Exemplo de VIF gerado:  

| Vari√°vel                           | VIF        |
|-----------------------------------|-----------|
| const                              | 31.308484 |
| Charges.Monthly                    | 22.356986 |
| InternetService_Fiber optic        | 7.554042  |
| tenure                             | 2.784158  |
| Contract_Two year                  | 2.610640  |
| StreamingMovies_Yes                | 2.417216  |
| StreamingTV_Yes                    | 2.400758  |
| PaymentMethod_Electronic check     | 1.973409  |
| TechSupport_Yes                    | 1.850009  |
| PaymentMethod_Mailed check         | 1.840793  |
| OnlineSecurity_Yes                 | 1.810495  |
| DeviceProtection_Yes               | 1.784591  |
| OnlineBackup_Yes                   | 1.708249  |
| MultipleLines_Yes                  | 1.630113  |
| Contract_One year                  | 1.620312  |
| PhoneService_Yes                   | 1.609719  |
| PaymentMethod_Credit card (automatic) | 1.560356 |
| Partner_Yes                        | 1.462143  |
| Dependents_Yes                     | 1.383601  |
| PaperlessBilling_Yes               | 1.208148  |
| SeniorCitizen                      | 1.153343  |
| gender_Male                        | 1.001830  |

--- 
### üìä Matriz de confus√£o e m√©tricas de avalia√ß√£o 

A matriz de confus√£o √© importante porque permite avaliar detalhadamente o desempenho de um modelo de classifica√ß√£o, mostrando quantos casos foram corretamente ou incorretamente classificados para cada classe. Ela fornece insights sobre acertos, erros e desequil√≠brios entre classes, complementando m√©tricas como acur√°cia, precis√£o, recall e F1-score. 

O foco principal no projeto s√£o em clientes que abandonam o servi√ßo (Churn = 1) por√©m como naturalmente s√£o dados desbalanceados ou seja, a propor√ß√£o de clientes que abandonam √© menor do que a propor√ß√£o de clientes ativos foquei em encontrar o equilibrio nas metricas de avalia√ß√£o ao determinar os melhores modelos.  No contexto de previs√£o de churn, o **recall(sensibilidade) foi priorizado*** como m√©trica principal, pois representa a capacidade do modelo em identificar corretamente os clientes que realmente ir√£o cancelar o servi√ßo. Um recall elevado √© essencial, j√° que perder clientes sem detect√°-los gera impacto direto na receita e na reten√ß√£o.

Entretanto, ao priorizar o recall, existe um **trade-off** com a precis√£o (precision): o modelo pode classificar alguns clientes como churn (falsos positivos) mesmo que n√£o estejam em risco real. Apesar disso, esse custo tende a ser menos cr√≠tico para o neg√≥cio do que deixar de identificar clientes que efetivamente ir√£o sair. Em resumo, o foco foi maximizar a detec√ß√£o de clientes em risco, ainda que isso implique em abordagens de reten√ß√£o para alguns clientes que n√£o cancelariam(falsos positivos).

![](visualizations/confusion_matrix_logistic.png) 
  

--- 
![](visualizations/confusion_matrix_dt.png)  

--- 
![](visualizations/confusion_matrix_rf.png)    


--- 
![Curva ROC - Regress√£o log√≠stica](visualizations/roc_curve_logistic_r.png) 

--- 
![Curva ROC - Decision tree](visualizations/roc_curve_dt.png)  

--- 
![Curva ROC - Random Forest](visualizations/roc_curve_rf.png)   

--- 

### Escolha do Melhor Modelo 

Ap√≥s os testes comparativos, o Random Forest foi escolhido como melhor modelo para previs√£o de churn. Embora Logistic Regression e Decision Tree tamb√©m tenham apresentado bom desempenho, o Random Forest conseguiu combinar:

* Maior recall para a classe "Yes" (clientes em risco), foco principal no problema de churn.

* Equil√≠brio entre precis√£o e recall, evitando excesso de falsos positivos.

* Melhor f1-score geral para a classe "Yes", garantindo maior efetividade na detec√ß√£o dos clientes que provavelmente ir√£o cancelar.

O Dummy Classifier, usado como baseline, demonstrou que prever apenas a classe majorit√°ria (clientes que n√£o cancelam) n√£o atende ao objetivo do projeto, j√° que n√£o identificou nenhum churn real (recall = 0 para "Yes"). 

| Modelo              | Accuracy | Precision (Yes) | Recall (Yes) | F1-Score (Yes) | AUC  | AP   |
| ------------------- | -------- | --------------- | ------------ | -------------- | ---- | ---- |
| **Random Forest**   | **0.75** | **0.52**        | **0.81**     | **0.63**       | 0.84 | 0.66 |
| Logistic Regression | 0.74     | 0.51            | 0.79         | 0.62           | 0.84 | 0.66 |
| Decision Tree       | 0.73     | 0.49            | 0.81         | 0.61           | 0.83 | 0.61 |
| Dummy Classifier    | 0.73     | 0.00            | 0.00         | 0.00           | ‚Äì    | ‚Äì    |



‚û°Ô∏è Dessa forma, o **Random Forest** foi escolhido como o melhor modelo por apresentar melhor balanceamento entre as m√©tricas e maior capacidade de identificar clientes com risco real de evas√£o. 

---

## üìä An√°lise de Import√¢ncia das Vari√°veis 

![permutation importance - Regress√£o Log√≠stica](visualizations/permutation_importance_logistic.png)   

--- 

![permutation importance - Random Forest](visualizations/permutation_importance_rf.png)    

## üìà Principais efeitos esperados na empresa de telecom

Com base nos resultados que voc√™ obteve (onde o modelo especialmente Random Forest conseguiu bom recall para churn ‚ÄúYes‚Äù), os efeitos esperados seriam:

* Identifica√ß√£o antecipada de clientes em risco, como um radar: O modelo consegue detectar com razo√°vel precis√£o quais clientes t√™m alta chance de cancelar. Isso permite a√ß√µes preventivas.

* A√ß√µes de reten√ß√£o direcionadas: A empresa pode focar em clientes com maior probabilidade de churn, reduzindo custos em campanhas gen√©ricas.

* Otimiza√ß√£o de recursos: Em vez de oferecer descontos ou benef√≠cios a todos, o time de reten√ß√£o foca nos clientes cr√≠ticos, aumentando ROI.

* Aprimoramento de ofertas e servi√ßos: Vari√°veis importantes como tenure, contract type e monthly charges indicam perfis de maior risco. Esses insights ajudam a revisar pol√≠ticas de contratos, pre√ßos ou planos.

Em um contexto real, isso se traduz na capacidade de a empresa de telecom implementar a√ß√µes proativas e personalizadas de reten√ß√£o, aumentando a probabilidade de manter clientes de alto valor. Se a empresa conseguir reter apenas uma fra√ß√£o dos clientes em risco, o impacto financeiro j√° √© significativo: maior receita preservada, menor taxa de evas√£o e aumento no valor de vida do cliente (LTV). Isso coloca a √°rea de neg√≥cios em uma posi√ß√£o mais competitiva e orientada a dados para tomadas de decis√£o.

## üöÄ Pr√≥ximos passos e melhorias
* Otimizar hiperpar√¢metros
* Treinar outros modelos de machine learning poss√≠veis como XGBoost com foco na melhora de performance preditiva.
* Feature engineering
