# üìä Telecom X ‚Äì Parte 2: Previs√£o de Evas√£o de Clientes (Churn)  
--- 
## üìå Descri√ß√£o do Projeto
 Este projeto √© a parte 2 de uma an√°lise explorat√≥ria dos dados onde nessa etapa iremos construir modelos de machine learning para previs√£o de evas√£o de clientes de uma empresa de telecomunica√ß√µes. Utilizamos t√©cnicas avan√ßadas de an√°lise de dados, machine learning e balanceamento de dados para identificar os principais fatores e padr√µes que contribuem para evas√£o de clientes. 

 ## Tecnologias Utilizadas
* Python 3.x
* Pandas, NumPy (manipula√ß√£o e an√°lise de dados)
* Matplotlib
* Scikit-learn

 ## ü§ñ Modelos de Machine learning
  * DummyRegressor (modelo baseline)
  * Decision Tree
  * Regress√£o Log√≠stica
  * Random Forest

## An√°lise dos Modelos Treinados 

![](visualizations/confusion_matrix_logistic.png) 

--- 
![](visualizations/confusion_matrix_dt.png)  

--- 
![](visualizations/confusion_matrix_rf.png)   

--- 
![Curva ROC - Regress√£o log√≠stica](visualizations/roc_curve_logistic_r.png) 

--- 
![Curva ROC - Decision tree](visualizations/roc_curve_dt.png)  

--- 
![Curva ROC - Random Forest](visualizations/roc_curve_rf.png)  

## An√°lise de Import√¢ncia das Vari√°veis 

![permutation importance - Regress√£o Log√≠stica](visualizations/permutation_importance_logistic.png)   

--- 

![permutation importance - Random Forest](visualizations/permutation_importance_rf.png)    

## Desempenho dos Modelos

Os modelos com melhor desempenho foram: Random Forest e Regress√£o Log√≠stica, estes apresentaram desempenho consistente na previs√£o de clientes propensos a churn:

**Recall(m√©trica principal neste projeto)**: alta capacidade de identificar clientes que realmente cancelariam, permitindo a√ß√µes preventivas mais eficazes.

**Precis√£o e F1-score**: equil√≠brio adequado entre falsos positivos e falsos negativos.

**AUC-ROC**: [ex.: 0.84], indicando bom poder discriminativo do modelo.

Estes modelos mostraram-se robustos e interpret√°veis, sendo poss√≠vel extrair insights das vari√°veis mais importantes para o neg√≥cio.  

## Pr√≥ximos passos 
* Otimizar hiperpar√¢metros
* Treinar outros modelos de machine learning poss√≠veis como XGBoost com foco na melhora de performance preditiva.
* Feature engineering
